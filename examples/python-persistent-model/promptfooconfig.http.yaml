# yaml-language-server: $schema=https://promptfoo.dev/config-schema.json
description: Persistent model loading using HTTP provider

# Alternative configuration using promptfoo's built-in HTTP provider
# This approach doesn't require a custom Python provider script

providers:
  - id: http://localhost:5000/generate
    label: Llama (HTTP Direct)
    config:
      method: POST
      headers:
        Content-Type: application/json
      body:
        prompt: '{{prompt}}'
        config:
          max_length: 150
          temperature: 0.8
          top_p: 0.95
      transformResponse: 'json.output'
      timeout: 30000  # timeout in milliseconds

prompts:
  - 'Write a creative story about {{topic}}:'
  - 'Generate a poem about {{topic}}:'
  - 'Describe {{topic}} in a fantasy setting:'

tests:
  - vars:
      topic: 'a robot learning to paint'
    assert:
      - type: contains
        value: 'robot'
      - type: javascript
        value: 'output.length > 50'

  - vars:
      topic: 'a magical forest'
    assert:
      - type: contains-any
        value: ['forest', 'tree', 'magical', 'enchanted']
      - type: javascript
        value: 'output.length > 50'

  - vars:
      topic: 'time travel paradoxes'
    assert:
      - type: contains-any
        value: ['time', 'paradox', 'past', 'future']
      - type: javascript
        value: 'output.length > 50'

  - vars:
      topic: 'an underwater city'
    assert:
      - type: contains-any
        value: ['water', 'ocean', 'sea', 'underwater', 'city']
      - type: javascript
        value: 'output.length > 50'
