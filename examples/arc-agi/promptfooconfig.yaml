# yaml-language-server: $schema=https://promptfoo.dev/config-schema.json
description: Evaluate AI models on ARC-AGI tasks

prompts:
  # Direct prompting strategy
  - id: direct-prompt
    label: |
      You are solving an ARC-AGI (Abstraction and Reasoning Corpus) task. These tasks test your ability to identify patterns and apply them to new situations.

      I will show you several input-output grid examples, then ask you to predict the output for a test input grid.

      Each grid is represented as a 2D array where each cell contains a number from 0-9, representing different colors:
      - 0: Black
      - 1: Blue  
      - 2: Red
      - 3: Green
      - 4: Yellow
      - 5: Grey/Gray
      - 6: Magenta/Pink
      - 7: Orange
      - 8: Sky/Light Blue
      - 9: Brown

      Training examples:
      {{training_examples}}

      Now, given this test input:
      {{test_input}}

      What is the output grid? Return ONLY the output grid as a JSON array, with no explanation or other text.

  # Chain of thought reasoning strategy
  - id: cot-reasoning
    label: |
      You are solving an ARC-AGI (Abstraction and Reasoning Corpus) task. These tasks test your ability to identify patterns and apply them to new situations.

      I will show you several input-output grid examples, then ask you to predict the output for a test input grid.

      Each grid is represented as a 2D array where each cell contains a number from 0-9, representing different colors:
      - 0: Black
      - 1: Blue  
      - 2: Red
      - 3: Green
      - 4: Yellow
      - 5: Grey/Gray
      - 6: Magenta/Pink
      - 7: Orange
      - 8: Sky/Light Blue
      - 9: Brown

      Training examples:
      {{training_examples}}

      Now, given this test input:
      {{test_input}}

      Think step by step:
      1. First, analyze what changes between input and output in the training examples
      2. Identify the pattern or rule being applied
      3. Apply this rule to the test input

      Show your reasoning, then provide the final output grid.

      <reasoning>
      [Your step-by-step reasoning here]
      </reasoning>

      <output>
      [The output grid as a JSON array]
      </output>

  # Program synthesis strategy
  - id: program-synthesis
    label: |
      You are solving an ARC-AGI (Abstraction and Reasoning Corpus) task by writing a program that transforms inputs to outputs.

      I will show you several input-output grid examples. Your goal is to write a Python function that takes an input grid and returns the correct output grid.

      Each grid is represented as a 2D array where each cell contains a number from 0-9, representing different colors.

      Training examples:
      {{training_examples}}

      Write a Python function `transform(input_grid)` that takes an input grid (2D list) and returns the output grid (2D list).

      Think about what transformation is being applied in the examples, then implement it.

      ```python
      def transform(input_grid):
          # Your implementation here
          pass
      ```

      After writing the function, apply it to this test input and return the result:
      {{test_input}}

      Return your complete solution including the function and the final output.

providers:
  # Claude models
  - anthropic:claude-3-5-sonnet-20241022
  - anthropic:claude-3-5-haiku-20241022
  
  # OpenAI models  
  - openai:gpt-4o-mini
  - openai:o1-mini

  # Open source models
  - ollama:llama3.3:latest

tests:
  # Sample test with a simple ARC-AGI task
  - vars:
      task_file: file://tasks/grid/sample_task_1.json
      training_examples:
        __js: |
          const task = JSON.parse(context.vars.task_file);
          return JSON.stringify(task.train.map((ex, i) => ({
            example: i + 1,
            input: ex.input,
            output: ex.output
          })), null, 2);
      test_input:
        __js: |
          const task = JSON.parse(context.vars.task_file);
          return JSON.stringify(task.test[0].input, null, 2);
      expected_output:
        __js: |
          const task = JSON.parse(context.vars.task_file);
          return task.test[0].output;

    assert:
      # Check if the output matches exactly
      - type: javascript
        value: |
          // Extract the output from the response
          let predicted;
          
          // Handle different response formats
          if (output.includes('<output>')) {
            // Extract from XML tags
            const match = output.match(/<output>([\s\S]*?)<\/output>/);
            if (match) {
              predicted = JSON.parse(match[1].trim());
            }
          } else if (output.includes('```json')) {
            // Extract from code block
            const match = output.match(/```json\s*([\s\S]*?)\s*```/);
            if (match) {
              predicted = JSON.parse(match[1]);
            }
          } else if (output.includes('```python')) {
            // For program synthesis, try to extract the final output
            const match = output.match(/(?:output|result)\s*=\s*(\[\[[\s\S]*?\]\])/);
            if (match) {
              predicted = JSON.parse(match[1].replace(/'/g, '"'));
            }
          } else {
            // Try to parse the entire output as JSON
            try {
              predicted = JSON.parse(output);
            } catch (e) {
              // Try to find a JSON array in the output
              const match = output.match(/\[\[[\s\S]*?\]\]/);
              if (match) {
                predicted = JSON.parse(match[0]);
              }
            }
          }
          
          if (!predicted) {
            return {
              pass: false,
              score: 0,
              reason: 'Could not extract a valid output grid from the response'
            };
          }
          
          const expected = context.vars.expected_output;
          
          // Check if dimensions match
          if (predicted.length !== expected.length || 
              predicted[0]?.length !== expected[0]?.length) {
            return {
              pass: false,
              score: 0,
              reason: `Dimension mismatch. Expected ${expected.length}x${expected[0].length}, got ${predicted.length}x${predicted[0]?.length || 0}`
            };
          }
          
          // Calculate pixel accuracy
          let correct = 0;
          let total = 0;
          
          for (let i = 0; i < expected.length; i++) {
            for (let j = 0; j < expected[i].length; j++) {
              total++;
              if (predicted[i][j] === expected[i][j]) {
                correct++;
              }
            }
          }
          
          const accuracy = correct / total;
          const pass = accuracy === 1.0;
          
          return {
            pass,
            score: accuracy,
            reason: pass ? 'Perfect match!' : `Pixel accuracy: ${(accuracy * 100).toFixed(1)}%`
          };

  # Add more test cases with different tasks
  - vars:
      task_file: file://tasks/grid/sample_task_2.json
      training_examples:
        __js: |
          const task = JSON.parse(context.vars.task_file);
          return JSON.stringify(task.train.map((ex, i) => ({
            example: i + 1,
            input: ex.input,
            output: ex.output
          })), null, 2);
      test_input:
        __js: |
          const task = JSON.parse(context.vars.task_file);
          return JSON.stringify(task.test[0].input, null, 2);
      expected_output:
        __js: |
          const task = JSON.parse(context.vars.task_file);
          return task.test[0].output;
    assert:
      - type: javascript
        value: file://evaluators/arc_grid_evaluator.js 