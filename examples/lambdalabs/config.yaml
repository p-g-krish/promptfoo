# yaml-language-server: $schema=https://promptfoo.dev/config-schema.json
description: Comparing Lambda Labs models

# To use this example:
# 1. Set your LAMBDA_API_KEY environment variable
# 2. Run: promptfoo eval --config examples/lambdalabs/config.yaml

prompts:
  - |
    You are an AI assistant with expertise in {{topic}}. Provide a concise explanation 
    of {{concept}} and its importance in the field.
    
    Please explain {{concept}} in the context of {{topic}} in simple terms.

providers:
  - id: lambdalabs:chat:llama-4-maverick-17b-128e-instruct-fp8
    config:
      temperature: 0.7
      max_tokens: 1024
  - id: lambdalabs:chat:llama3.3-70b-instruct-fp8
    config:
      temperature: 0.7
      max_tokens: 1024

defaultTest:
  assert:
    - type: javascript
      value: "return output.length > 100 ? 'pass' : 'fail'; // Ensure we get substantial responses"

tests:
  - vars:
      topic: quantum computing
      concept: quantum entanglement
    assert:
      - type: llm-rubric
        value: "Does the response explain quantum entanglement clearly? Rate from 1-10."
      - type: contains-any
        value: ["entangled", "correlated", "quantum state"]
  - vars:
      topic: machine learning
      concept: neural networks
    assert:
      - type: llm-rubric
        value: "Does the response explain neural networks clearly? Rate from 1-10."
      - type: contains-any
        value: ["neurons", "weights", "layers", "activation"]
  - vars:
      topic: astronomy
      concept: dark matter
    assert:
      - type: llm-rubric
        value: "Does the response explain dark matter clearly? Rate from 1-10."
      - type: contains-any
        value: ["gravity", "mass", "invisible", "galaxy"]
  - vars:
      topic: quantum physics
      concept: wave-particle duality
    assert:
      - type: llm-rubric
        value: "Does the response explain wave-particle duality clearly? Rate from 1-10." 