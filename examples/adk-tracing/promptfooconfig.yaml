# yaml-language-server: $schema=https://promptfoo.dev/config-schema.json
description: ADK Tracing Example with Real LLM Calls

providers:
  - python:provider.py

prompts:
  - 'Research the topic: {{topic}}'

tests:
  - vars:
      topic: quantum computing advances
    assert:
      - type: contains
        value: 'Executive Summary'
      - type: contains
        value: 'Main Points'
      - type: contains
        value: 'quantum'

  - vars:
      topic: renewable energy breakthroughs
    assert:
      - type: contains
        value: 'Executive Summary'
      - type: contains
        value: 'Main Points'
      - type: contains-any
        value: ['renewable', 'energy', 'solar', 'wind']

  - vars:
      topic: artificial intelligence safety
    assert:
      - type: contains
        value: 'Executive Summary'
      - type: contains
        value: 'Conclusion'
      - type: contains-any
        value: ['AI', 'artificial intelligence', 'safety', 'risk']

# Enable OpenTelemetry tracing
tracing:
  enabled: true
  otlp:
    http:
      enabled: true
      port: 4318
      host: 0.0.0.0
      acceptFormats: ['json', 'protobuf']
