---
sidebar_position: 2
title: Types of LLM Vulnerabilities
description: Comprehensive guide to categories of LLM vulnerabilities and failure modes that can be tested with promptfoo
keywords: [llm security, red teaming, llm vulnerabilities, ai safety testing, prompt injection]
---

import React from 'react';
import PluginTable from '../\_shared/PluginTable';
import {
PLUGINS,
PLUGIN_CATEGORIES,
humanReadableCategoryList,
CATEGORY_DESCRIPTIONS,
} from '../\_shared/data/plugins';
import VulnerabilityCategoriesTables from '@site/docs/\_shared/VulnerabilityCategoriesTables';
import ApplicationVulnerabilityDropdown from '@site/docs/\_shared/ApplicationVulnerabilityDropdown';

# Types of LLM Vulnerabilities

Large Language Models (LLMs) can exhibit a wide range of vulnerabilities that affect their safety, security, and reliability. Understanding these vulnerability categories is essential for comprehensive testing and securing your LLM applications.

This page documents the major categories of potential LLM vulnerabilities and failure modes, providing a framework for systematic testing and mitigation strategies.

## Introduction to LLM Vulnerabilities

LLM vulnerabilities can manifest in various ways, from security issues like prompt injection to harmful content generation. Each vulnerability type represents a distinct risk to LLM applications that should be proactively tested and mitigated.

Promptfoo's open-source [plugins](/docs/red-team/plugins/) provide a modular system for testing these risks and vulnerabilities in your LLM models and applications. To get started with vulnerability testing, see our [quickstart guide](/docs/red-team/quickstart/).

![LLM vulnerability categories and their relationships](/img/docs/llm-vulnerability-types.svg)

## Specialized Testing Guides

For more targeted testing of specific LLM deployment types, see our specialized guides:

- [Red teaming AI agents](/docs/red-team/agents/) - Test autonomous LLM systems
- [Red teaming RAGs](/docs/red-team/rag/) - Evaluate retrieval-augmented generation systems
- [Red teaming multi-modal models](/docs/guides/multimodal-red-team) - Test models that process images, audio, and other modalities
- [Testing and validating guardrails](/docs/guides/testing-guardrails/) - Verify safety mechanisms

## Vulnerability Categories

### Technical Security Vulnerabilities

Technical security vulnerabilities focus on attack vectors that compromise system integrity, confidentiality, or availability through manipulation of the model's behavior or exploiting architectural weaknesses.

<VulnerabilityCategoriesTables vulnerabilityType="security" showSeverity={true} showCategory={true} />

### Information Exposure Risks

Information exposure vulnerabilities involve the inadvertent disclosure of sensitive information, including personal data, training data, or confidential information that shouldn't be shared through interaction with the LLM.

<VulnerabilityCategoriesTables vulnerabilityType="privacy" showSeverity={true} showCategory={true} />

### Content Safety Issues

Content safety issues involve the generation of potentially harmful, offensive, or dangerous content that could cause physical, emotional, or psychological harm to individuals or groups. These may expose organizations to reputational or legal risks.

<VulnerabilityCategoriesTables vulnerabilityType="harmful" showSeverity={true} showCategory={true} />

### Truth and Accuracy Problems

Truth and accuracy vulnerabilities relate to the generation of factually incorrect, misleading, or deceptive information that could lead to misinformed decisions or actions. This includes hallucinations, fabrications, and other forms of generated misinformation.

<VulnerabilityCategoriesTables vulnerabilityType="misinformation and misuse" showSeverity={true} showCategory={true} />

### Compliance and Legal Risks

Compliance and legal risks involve the model producing outputs that may violate laws, regulations, or contractual obligations. This includes content that facilitates illegal activities, copyright violations, or unauthorized commitments.

<VulnerabilityCategoriesTables vulnerabilityType="criminal" showSeverity={true} showCategory={true} />

## Vulnerability Classification Framework

The taxonomy above organizes vulnerabilities by their primary risk domain. This approach helps organizations:

1. **Map to Organizational Responsibilities**: Different teams (security, legal, trust & safety) can focus on their relevant domains
2. **Prioritize by Risk Type**: Address critical security issues separately from content concerns
3. **Design Targeted Mitigations**: Apply the right countermeasures for each vulnerability class
4. **Match Regulatory Requirements**: Align testing with specific compliance obligations

This classification represents the most common risk domains, but some vulnerabilities may span multiple categories. For comprehensive testing, consider evaluating all applicable domains for your specific application.

## Vulnerabilities by Application Type

Not all applications are vulnerable to every type of exploit. Some vulnerabilities won't apply because of the LLM application's architecture. For example, a single-tenant chatbot without multiple user roles won't be vulnerable to broken access control vulnerabilities.

Select an application type below to see which vulnerabilities are most relevant:

<ApplicationVulnerabilityDropdown />

## Testing for Vulnerabilities

To effectively test for these vulnerabilities:

1. **Identify relevant vulnerability types** for your specific application
2. **Select appropriate plugins** that test for those vulnerabilities
3. **Configure test strategies** to maximize the effectiveness of your testing
4. **Run comprehensive evaluations** using promptfoo's red teaming capabilities
5. **Analyze results** to identify and prioritize necessary mitigations

## Plugin Reference

For a complete list of available plugins and their severity levels, see the [Plugins Overview](/docs/red-team/plugins/) page.

## Related Concepts

- [Red Teaming Strategies](/docs/red-team/strategies/) - Techniques for testing LLM vulnerabilities
- [Red Teaming Plugins](/docs/red-team/plugins/) - Tools for generating test cases
- [Evaluation Assertions](/docs/configuration/expected-outputs/) - Methods for validating outputs
- [Security Best Practices](/docs/guides/best-practices/) - Guidelines for securing LLM applications
